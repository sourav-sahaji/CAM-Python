{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "try:\n",
    "\tcaffe_root = os.environ['CAFFE_ROOT'] + '/'\n",
    "except KeyError:\n",
    "  \traise KeyError(\"Define CAFFE_ROOT in ~/.bashrc\")\n",
    "\n",
    "sys.path.insert(1, caffe_root+'python/')\n",
    "import caffe\n",
    "import cv2\n",
    "from py_returnCAMmap import py_returnCAMmap\n",
    "from py_map2jpg import py_map2jpg\n",
    "import scipy.io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def im2double(im):\n",
    "\treturn cv2.normalize(im.astype('float'), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
    "\n",
    "## Be aware that since Matlab is 1-indexed and column-major, \n",
    "## the usual 4 blob dimensions in Matlab are [width, height, channels, num]\n",
    "\n",
    "## In python the dimensions are [num, channels, width, height]\n",
    "\n",
    "model = 'googlenet'\n",
    "if model == 'alexnet':\n",
    "\tnet_weights = 'models/alexnetplusCAM_imagenet.caffemodel'\n",
    "\tnet_model = 'models/deploy_alexnetplusCAM_imagenet.prototxt'\n",
    "\tout_layer = 'fc9'\n",
    "\tlast_conv = 'conv7'\n",
    "\tcrop_size = 227\n",
    "elif model == 'googlenet':\n",
    "# \tnet_weights = 'models/imagenet_googleletCAM_train_iter_120000.caffemodel'\n",
    "# \tnet_model = 'models/deploy_googlenetCAM.prototxt'\n",
    "\tnet_weights = 'models/places_googleletCAM_train_iter_120000.caffemodel'\n",
    "\tnet_model = 'models/deploy_googlenetCAM_places205.prototxt'    \n",
    "\tout_layer = 'CAM_fc'\n",
    "\tcrop_size = 224\n",
    "\tlast_conv = 'CAM_conv'\n",
    "else:\n",
    "\traise Exception('This model is not defined')\n",
    "\n",
    "categoriesFile = [\"../dataset/slamData/categoryIndex_places205.csv\",\n",
    "                 \"../dataset/slamData/categories_places365.txt\",\n",
    "                 '../dataset/slamData/categories_hybrid1365.txt']\n",
    "\n",
    "categoriesNames = np.loadtxt(categoriesFile[0],dtype=str,delimiter='\\n')\n",
    "\n",
    "\n",
    "# load CAM model and extract features\n",
    "net = caffe.Net(net_model, net_weights, caffe.TEST)\n",
    "\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_mean('data', np.load(caffe_root + 'python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1))\n",
    "#transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n",
    "\n",
    "weights_LR = net.params[out_layer][0].data # get the softmax layer of the network\n",
    "print(\"Weights\",weights_LR.shape)\n",
    "# shape: [1000, N] N-> depends on the network\n",
    "\n",
    "\n",
    "def getScoresAndLastConvAct(img):\n",
    "\n",
    "    # Take center crop.\n",
    "    center = np.array(img.shape[:2]) / 2.0\n",
    "    crop = np.tile(center, (1, 2))[0] + np.concatenate([\n",
    "        -np.array([crop_size, crop_size]) / 2.0,\n",
    "        np.array([crop_size, crop_size]) / 2.0\n",
    "    ])\n",
    "    crop = crop.astype(int)\n",
    "    input_ = img#[crop[0]:crop[2], crop[1]:crop[3], :]\n",
    "\n",
    "#     plt.imshow(input_)\n",
    "#     plt.show()\n",
    "    # extract conv features\n",
    "    net.blobs['data'].reshape(*np.asarray([1,3,crop_size,crop_size])) # run only one image\n",
    "    net.blobs['data'].data[...][0,:,:,:] = transformer.preprocess('data', input_)\n",
    "    out = net.forward()\n",
    "    scores1 = out['prob']\n",
    "    activation_lastconv = net.blobs[last_conv].data\n",
    "#     print(\"Act_lastConv\", activation_lastconv.shape)\n",
    "    \n",
    "    return scores1, activation_lastconv\n",
    "\n",
    "\n",
    "def getCAM(img,scores1,activation_lastconv1,showActs=False):\n",
    "\n",
    "    ## Class Activation Mapping\n",
    "\n",
    "    topNum = 5 # generate heatmap for top X prediction results\n",
    "    scoresMean = np.mean(scores1, axis=0)\n",
    "    ascending_order = np.argsort(scoresMean)\n",
    "    IDX_category = ascending_order[::-1] # [::-1] to sort in descending order\n",
    "\n",
    "#     IDX_category = [92,98,151,16,170]\n",
    "#     IDX_category = [92,60,67,79,78]\n",
    "    \n",
    "    curCAMmapAll = py_returnCAMmap(activation_lastconv1, weights_LR[IDX_category[:topNum],:])\n",
    "    print(\"camALl\",curCAMmapAll.shape)\n",
    "\n",
    "    curResult = im2double(img)\n",
    "\n",
    "    avgHeatMap = []\n",
    "    for j in range(topNum):\n",
    "        # for one image\n",
    "        curCAMmap_crops = curCAMmapAll[:,:,j]\n",
    "#         plt.imshow(curCAMmap_crops)\n",
    "#         plt.colorbar()\n",
    "#         plt.show()\n",
    "        curCAMmapLarge_crops = cv2.resize(curCAMmap_crops, (256,256))\n",
    "        imgWrite = cv2.normalize(curCAMmap_crops.astype('float'), None, 0.0, 255.0, cv2.NORM_MINMAX)\n",
    "        cv2.imwrite(\"./bboxgenerator/heatmaps/\"+str(j)+\".jpg\",imgWrite)\n",
    "        curHeatMap = cv2.resize(im2double(curCAMmapLarge_crops),(256,256)) # this line is not doing much\n",
    "        curHeatMap = im2double(curHeatMap)\n",
    "\n",
    "        curHeatMap = py_map2jpg(curHeatMap, None, 'jet')\n",
    "        curHeatMap = im2double(img)*0.2+im2double(curHeatMap)*0.7\n",
    "        \n",
    "        if showActs:\n",
    "            plt.imshow(curHeatMap)\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "            print(categoriesNames[IDX_category[j]])\n",
    "        #   cv2.imshow(categories['categories'][IDX_category[j]][0][0], curHeatMap)\n",
    "        #   cv2.waitKey(0)\n",
    "            avgHeatMap.append(curHeatMap)\n",
    "\n",
    "    if showActs:\n",
    "        plt.imshow(np.mean(np.array(avgHeatMap),axis=0))\n",
    "        plt.colorbar()\n",
    "        plt.show()\n",
    "    return curCAMmapAll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Image Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### image = cv2.imread('img2.jpg')\n",
    "image = cv2.imread('../dataset/slamData/oxford/camTests/5-0001882.png')\n",
    "# image = cv2.imread('../dataset/models/places-cnn/signBoard.png')\n",
    "print(image.shape)\n",
    "\n",
    "# image = cv2.resize(image[:810,:,:], (427, 270))[:,75:-75]\n",
    "image = cv2.resize(image[:810,:,:],(256,256))\n",
    "cv2.imwrite(\"./bboxgenerator/heatmaps/\"+str(1)+\"-raw.jpg\",cv2.resize(image,(14,14)))\n",
    "print(image.shape)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "scores, activation_lastconv = getScoresAndLastConvAct(image)\n",
    "camFeats = getCAM(image,scores,activation_lastconv,showActs=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check weight patterns for similar classes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "classInds = [92,60,151,120,135]\n",
    "weightsForClasses = weights_LR[classInds,:]\n",
    "topUnits = np.argsort(weightsForClasses,axis=1)[:,-20:]\n",
    "print(categoriesNames[classInds])\n",
    "print(np.sort(topUnits,axis=1))\n",
    "\n",
    "# top n units with highest activation\n",
    "print(activation_lastconv.shape)\n",
    "acts = np.mean(activation_lastconv[0,:,:,:].reshape(weights_LR.shape[1],-1),axis=1)\n",
    "topUnitsAct = np.argsort(acts)[-10:]\n",
    "print(topUnitsAct)\n",
    "\n",
    "for unit in topUnitsAct:#topUnits[0,-10:]:\n",
    "    plt.imshow(activation_lastconv[0,unit,:,:])\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[1010  965  732  836  548  794  986  530  802  979]\n",
    "[1005  570 1004  605  732  742  530  986  979  802]\n",
    "[687 742 979 726 732 986 802 570 530 626]\n",
    "[313 538 445 802 409 986 820 969 535 687]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "folderPath = '../dataset/slamData/oxford/camTests/'\n",
    "imageNames = os.listdir(folderPath)\n",
    "print(imageNames)\n",
    "camFeatsImgs = []\n",
    "for imageName in imageNames:\n",
    "    image = cv2.imread(folderPath+imageName)\n",
    "    image = cv2.resize(image[:800,:,:], (256, 256))\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    scores, activation_lastconv = getScoresAndLastConvAct(image)\n",
    "    camFeats = getCAM(image,scores,activation_lastconv,showActs=False)\n",
    "    camFeatsImgs.append(camFeats.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from a folder and store features for all images using one file per semantic category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oxDataFolders = [\"2014-12-09-13-21-02/\",\"2014-12-10-18-10-50/\",\"2014-12-16-09-14-09/\",\"2015-02-03-08-45-10/\",\n",
    "                \"2015-05-19-14-06-38/\"]\n",
    "cameraTypes = [\"mono_rear_rect/\",\"stereo/left_rect/\"]\n",
    "resizeVals = [(512,512),(512,384)]\n",
    "dataNum = 4\n",
    "cameraNum = 1\n",
    "resizeNum = 1\n",
    "folderPath = '../dataset2/current/data/oxford/' + oxDataFolders[dataNum] + cameraTypes[cameraNum]\n",
    "cameraTypes[1] = \"stereo_left_rect/\"\n",
    "\n",
    "sampleIndsFile = \"../dataset/slamData/oxford/samples/\" + str(dataNum+1) + \"-\" + cameraTypes[cameraNum][:-1] + \"-sampledInds.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Reading file - \", sampleIndsFile)\n",
    "sampledInds = np.loadtxt(sampleIndsFile)\n",
    "imageNameFmt = '{0:07d}'\n",
    "print(\"Num Samples - \",sampledInds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "camFeatsImgs = []\n",
    "for i in range(sampledInds.shape[0]):\n",
    "    index = int(sampledInds[i])\n",
    "    imageName = folderPath + imageNameFmt.format(index) + \".png\"\n",
    "    image = cv2.imread(imageName)\n",
    "    image = cv2.resize(image, resizeVals[resizeNum])[:320,:]\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()\n",
    "#     %time    \n",
    "    scores, activation_lastconv = getScoresAndLastConvAct(image)\n",
    "    time.sleep(0.1)\n",
    "    camFeat = py_returnCAMmap(activation_lastconv, weights_LR)\n",
    "    shp = camFeat.shape\n",
    "    camFeatReshaped = camFeat.transpose([2,0,1]).reshape(shp[2],shp[0]*shp[1])\n",
    "    camFeatsImgs.append(camFeatReshaped)\n",
    "#     print(camFeatReshaped.shape)\n",
    "\n",
    "    if i%20 == 0:\n",
    "        print(i,\" images read.\")\n",
    "print(np.array(camFeatsImgs).shape)\n",
    "featureArr = np.array(camFeatsImgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataStr = str(dataNum+1) + \"-\" + cameraTypes[cameraNum][:-1]\n",
    "outFolderPath = \"../dataset/slamData/oxford/labels-ConvCAM/\" \n",
    "os.mkdir(outFolderPath+dataStr)\n",
    "outFolderPath = outFolderPath + dataStr + \"/\"\n",
    "for i in range(weights_LR.shape[0]):\n",
    "    filePath = outFolderPath + str(i) + \".txt\"\n",
    "    np.savetxt(filePath,featureArr[:,i,:],fmt='%f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Matrix\n",
    "copied from semanticPlaceRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getCostMatrix(probMat1,probMat2):\n",
    "    \n",
    "    newDiffMat = np.ndarray([probMat1.shape[0],probMat2.shape[0]])\n",
    "    rowCounter = 0\n",
    "\n",
    "    for a_row in probMat1:\n",
    "#         newDiffMat[rowCounter,:] = np.dot(probMat2,a_row[:,...]) / np.square(probMat1.shape[1])\n",
    "        newDiffMat[rowCounter,:] = (np.arccos(np.dot(probMat2,a_row[:,...]) / (np.linalg.norm(probMat2,axis=1)*\n",
    "                                                                           np.linalg.norm(a_row))))/np.pi\n",
    "#         newDiffMat[rowCounter,:] = np.linalg.norm(probMat2-a_row[:,...],axis=1)\n",
    "#         newDiffMat[rowCounter,:] = np.sum(np.divide(abs(probMat2-a_row[:,...]),probMat2),axis=1)\n",
    "        \n",
    "        rowCounter+=1\n",
    "    assert(rowCounter==probMat1.shape[0])\n",
    "    \n",
    "    return newDiffMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "camFeatsImgs2 = (camFeatsImgs - np.mean(camFeatsImgs,axis=0))/np.var(camFeatsImgs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print(np.mean(act_pool1),np.mean(act_pool2))\n",
    "# print(np.argsort(act_pool1[92,:])[-10:],np.argsort(act_pool2[92,:])[-10:])\n",
    "diff = getCostMatrix(np.array(camFeatsImgs2),np.array(camFeatsImgs2))\n",
    "# print(diff)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(diff,'hot')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "# plt.imshow(act_pool1[:,500:600])\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
